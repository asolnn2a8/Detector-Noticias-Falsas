\section{Introducción}
{
% Debe mencionar las motivaciones de realizar este proyecto, definir sus objetivos, qué busca
% resolver o demostrar y una explicación general del trabajo realizado.

% Contexto de las noticias actualmente
En la actualidad, los usuarios de internet, se encuentran constantemente bombardeados de información y noticias, de fuentes que parecen diversificarse igual de rápido que el internet mismo. 

% Importancia para resolver esto
Es por ello, que no siempre se puede identificar con certeza cuando una noticia es verdadera o falsa. Lo cual cobra importancia, ya que las noticias son la forma principal en que las personas pueden entender el contexto en que están viviendo y formar sus opiniones. Además de que las noticias falsas propagan desinformación y s

, y más aún si la persona quién está leyendo la noticia no tiene los conocimientos necesarios, o no ha desarrollado un pensamiento crítico para discernir cuando una noticia es verdadera o falsa.

% Objetivo
Es por esto que el objetivo de este trabajo es el de desarrollar una herramienta que permita \textbf{clasificar} una noticia como verdadera o falsa, en base a sus características.

Para esto, se utilizarán diversas herramientas clásicas de Aprendizaje de Máquinas, como lo es el Procesamiento de Lenguaje Natural, y Clasificación Binario.   


Es por esto que en este trabajo se explorarán métodos que permitirán verificar cuando una noticia es verdadera o falsa, utilizando las
herramientas de Aprendizaje de Máquinas. Es decir, \textbf{clasificaremos} una noticia como verdadera o falsa, en base a sus características.

% Origen de los datos
% Para esto, se obtendrán diversas noticias de US a través de 
% \href{https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset}{kaggle}, etiquetadas por verdaderas o falsas. 

}

\section{Marco Teórico}
{
\subsection{Herramientas de NLP}
El procesamiento del lenguaje natural investiga el uso de computadores para procesar o entender el lenguaje humano (natural) con el objetivo de realizar tareas útiles. Dentro de las aplicaciones más comunes están: reconocimiento de voz, interpretación del lenguaje hablado (SLU por sus siglas en inglés), sistemas de diálogos, análisis léxico, análisis gramatical, análisis sintáctico, análisis morfológico, traducciones, recuperación de texto, análisis de sentimientos, etc. 

Uno de los imperativos en el procesamiento de textos, es la vectorización. Ya que permite a la máquina entender el contenido simbólico a través de representaciones numéricas significativas. En el caso de la técnica usada, construye una matriz para registrar la frecuencia de cada componente léxico observado. 

Sin embargo, el trabajo requerido para convertir el texto natural en componentes léxicos que puedan aportar significado  la matriz no es trivial. Se ocupan técnicas de análisis léxico, análisis sintáctico y lematización. 

El análisis léxico del texto, corresponde a dividir oraciones o párrafos en componentes léxicos o símbolos. Para así poder visualizar individualmente las palabras o símbolos que componen una secuencia de texto. Luego, la lematización es el proceso mediante el cual las palabras de un texto que pertenecen a un mismo paradigma flexivo o derivativo son llevadas a una forma normal que representa a toda la clase. Esta forma normal, llamada lema, es típicamente la palabra utilizada como entrada en los diccionarios de lengua. En la lematización usada, se necesita distinguir si la palabra es un verbo, sustantivo, adjetivo o adverbio, para llevar a su raíz más exacta. Dicho proceso es el análisis sintáctico. 

Así, cada componente léxico corresponde a un lema. Lo cual permite agrupar de mejor manera las palabras por significado y otorga mayor importancia a cada representación en la vectorización. 

}

\section{Descripción de los Datos}
{
\subsection{Descripción del dataset}
La base de datos se obtuvieron a partir de Kaggle, del \textit{dataset} llamado ``\href{https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset}{Fake and 
real news dataset}''.

Esta base de datos consiste en dos \textit{datasets}: el de noticias falsas (17.903 datos) y el de noticias verdaderas (20.826 datos). Ambos datasets 
comparten las mismas columnas: \textit{title}, \textit{text}, \textit{subject} y \textit{date}. Estas corresponden al titular de
la noticia, al contenido de la noticia, al tipo de noticia que es y la fecha de la noticia, respectivamente.

Las columnas \textit{title} y \textit{text} son de tipo cadena; \textit{subject} es un tipo de dato categórico y \textit{date}
es un tipo de dato temporal. 

% \subsubsection{Descripción de las categorías de la columna \textit{subject}}
En el \textit{dataset} de las noticias verdaderas, existen dos etiquetas para la columna \textit{subject}, las cuales son \textbf{politicsNews} y \textbf{worldnews}. La etiqueta \textbf{politicsNews} posee 11.272 datos y es para referirse a las noticias que tengan una connotación política, mientras que la etiqueta \textbf{worldnews} posee 10.145 datos y es para referirse a las noticias que ocurren fuera de EE.UU.

Mientras que el \textit{dataset} de las noticias falsas, posee seis etiquetas:
\textbf{News}, \textbf{politics}, \textbf{Government News}, \textbf{left-news}, \textbf{US news} y \textbf{Middle-east}. A continuación se dará una breve descripción de cada categoría:
\begin{itemize}
    \item La etiqueta de \textbf{News} posee 9.050 datos y corresponde a las noticias estándar,
    \item La de \textbf{politics} posee 6.836 datos y corresponde a noticias de connotación política,
    \item La de \textbf{Government News} posee 1.568 datos y corresponde a noticias sobre el gobierno,
    \item La de \textbf{left-news} posee 4.456 datos y corresponde a noticias del espectro de la izquierda política,
    \item La de \textbf{US News} posee 784 datos y corresponde a noticias sobre EE.UU., y finalmente
    \item La de \textbf{Middle-east} posee 778 datos y corresponde a noticias del Oriente Medio.
\end{itemize}

El \textit{dataset} originalmente no posee valores nulos. Sin embargo, el \textit{dataset} de las noticias falsas posee 10 datos etiquetados como fecha, a pesar de que no lo sean.


\subsection{Tratamiento de los Datos}

Se crea una nueva columna en ambos \textit{datasets}, llamado \textit{true}, el cual determina si la noticia es verdadera o falsa. Creada la columna, se concatenan ambos \textit{datasets}. Además, se marcan los datos que no sean fechas de la columna \textit{date} por el tipo de dato llamado \textit{Not a Time}, y se eliminan los datos nulos que posea el \textit{dataset}.

Luego, se procederá a procesar la información de texto (esto es, para las columnas \textit{title} y \textit{text}) a través de NLP. Se escogerá una muestra de 2500 filas\footnote{Si se escogen más filas, la memoria para guardar la información del computador queda sobrecargada} de los datasets originales (para las noticias verdaderas y falsas) y se empieza por dejar el texto en minúsculas, luego se tokenizan, y por cada token, si es que no es una stopword, se lematiza, para finalmente unir todos los tokens lematizados en un único texto nuevamente, y esta información se reemplaza en dónde estaba la información no procesada.

Finalmente, se empieza a codificar la información a través de un vector de características. 

\subsection{Análisis Exploratorio de los Datos}

Una de las primeras preguntas que se puede realizar sobre
\begin{figure}
\centering
\begin{subfigure}{.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{imagenes/wordcloud_titulares_falsas.pdf}
    \caption{Titulares de noticias falsas}
    \label{fig:tit-fake}
\end{subfigure}%
\newline
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{imagenes/wordclouds_cuerpo_falsas.pdf}
    \caption{Cuerpo de noticias falsas}
    \label{fig:text-fake}
\end{subfigure}
\caption{Nube de palabras para las noticias falsas.}
\label{fig:fake}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.47\textwidth]{imagenes/wordcloud_titulares_falsas.pdf}
%     \caption{Titulares de noticias falsas}
%     \label{fig:tit-fake}
% \end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.47\textwidth]{imagenes/wordclouds_cuerpo_falsas.pdf}
%     \caption{Cuerpo de noticias falsas}
%     \label{fig:text-fake}
% \end{figure}

\begin{figure}
\centering
\begin{subfigure}{.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{imagenes/wordcloud_titulares_verdaderas.pdf}
    \caption{Titulares de noticias verdaderas}
    \label{fig:tit-true}
\end{subfigure}%
\newline
\begin{subfigure}{.5\textwidth}
    \centering
    \includegraphics[width=\textwidth]{imagenes/wordclouds_cuerpo_verdaderas.pdf}
    \caption{Cuerpo de noticias verdaderas}
    \label{fig:text-true}
\end{subfigure}
\caption{Nube de palabras para las noticias verdaderas.}
\label{fig:fake}
\end{figure}

% \begin{figure}
%     \centering
%     \includegraphics[width=0.47\textwidth]{imagenes/wordcloud_titulares_verdaderas.pdf}
%     \caption{Titulares de noticias verdaderas}
%     \label{fig:tit-true}
% \end{figure}
% \begin{figure}
%     \centering
%     \includegraphics[width=0.47\textwidth]{imagenes/wordclouds_cuerpo_verdaderas.pdf}
%     \caption{Cuerpo de noticias verdaderas}
%     \label{fig:text-true}
% \end{figure}
}

\section{Metodología}
{
\subsection{Modelos}
Se escogerán tres modelos: \textit{Naïve Bayes} (NB), por su simpleza, \textit{Regresión Logística} (RL), y el \textit{Perceptrón}, ambos modelos por su capacidad de predecir sin utilizar técnicas geométricas.

\subsubsection{Preparación del modelo de NB} 
Se escogerá un prior uniforme para Naïve Bayes.

\subsubsection{Preparación del modelo de RL}
No se ajustarán hiperparámetros para este modelo.

\subsubsection{Preparación del modelo de Perceptrón}
No se ajustarán hiperparámetros para este modelo.

\subsection{Preparación del Conjunto de Entrenamiento y Test}
Luego de procesada toda la información del texto, se escoge una columna para realizar la predicción. En nuestro caso, se escogen las columnas \textit{title}, \textit{text} (ambas por separado) y una concatenación de \textit{title} $+$ \textit{text}. 

Fijada una columna, se procede a dividir de forma aleatoria un $70\%$ de los datos para el entrenamiento, y un $30\%$ de los datos para el test.

}

\section{Resultados}
{
En la Tabla \ref{tab:resumen} se puede observar el porcentaje de precisión que resultó después de utilizar los tres modelos en cada una de las columnas.
\input{latex/tablas/tabla_resumen}

}

\section{Discusión y Conclusiones}
{

Observamos a partir de la Tabla \ref{tab:resumen} que, ocupando el modelo de \textit{Regresión Logística} sobre la columna de \textit{text} (procesada) es la que resulta con la mayor precisión entre todas combinaciones. 

Sin embargo, es destacable que ocupando únicamente el titular de la noticia, todos los modelos tengan aproximadamente un $90\%$ de precisión a la hora de predecir la veracidad de la misma. Lo cuál significa que, basta con recibir el titular de una noticia para determinar con bastante precisión si ésta es verdadera o falsa.

Además, es destacable que utilizando el titular de la noticia, junto con el texto de la misma, termina empeorando la calidad de la predicción en los tres modelos. Esto resulta contra intuitivo, pues se espera que añadiendo ``más información'' que puede resultar útil, realmente termine perjudicando la calidad de predicción.

\subsection{Futuras Mejoras}

Observamos que la división entre el conjunto de entrenamiento y de test no es la mejor forma de particionar los datos. Más que nada por el siguiente hecho: los datos son dependientes del tiempo. 

Esta dependencia temporal es lo que obliga a considerar el escenario de, ``estoy ocupando los datos del pasado para predecir el futuro'', con lo que una forma óptima de particionar los datos es la siguiente: ordenar los datos por fecha, y luego, dividir los primeros $x\%$ de los datos para el conjunto de entrenamiento, y los restantes $(100-x)\%$ como conjunto de test.
}

% \section{Desarrollo}
% {
% % El procedimiento y los experimentos realizados, descripción de los datos, la metodología usada, las
% % configuraciones (parámetros) de los algoritmos usados, etc. Explicar las decisiones que tomaron y el porqué. Si
% % usaron un algoritmo para resolver el problema, explicar su elección y por qué no otro. No es necesario que sea
% % una explicación rigurosa, puede ser por la naturaleza del problema, de forma intuitiva o por aspectos prácticos
% \subsection{Descripción de los datos}
% {
% Los datos se obtuvieron de la Base de Datos \href{https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset}{Fake and 
% real news dataset}, de kaggle. 

% Este consiste en dos datasets: el de noticias falsas (17903 datos) y el de noticias verdaderas (20826 datos). Ambos datasets 
% comparten las mismas columnas: \textit{title}, \textit{text}, \textit{subject} y \textit{date}. Estas corresponden al titular de
% la noticia, al contenido de la noticia, al tipo de noticia que es y la fecha de la noticia, respectivamente.

% Las columnas \textit{title} y \textit{text} son de tipo cadena; \textit{subject} es un tipo de dato categórico y \textit{date}
% es un tipo de dato temporal. 
% }
% }

% \section{Resultados y Análisis}
% {
% % Mostrar, explicar y discutir los resultados obtenidos. El análisis incluye una interpretación superficial (funcionó/no funcionó), y también un análisis de si era o no lo esperado, por qué, y qué
% % se podría mejorar
% \lipsum[3]
% }

% \section{Conclusión}
% {
% % Las conclusiones que se obtienen del proyecto (No ponga conclusiones del estilo ”aprendí mucho”).
% % Incluya las dificultades que se encontraron y propuestas de trabajo a futuro.
% \lipsum[4]
% }